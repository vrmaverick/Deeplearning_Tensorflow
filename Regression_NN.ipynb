{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We Will be implementing Regression using Neural Network , i.e Predicting values of dependent variable using independent input features"
      ],
      "metadata": {
        "id": "Ft9pH20qLrna"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyVfcf6q_-Oo",
        "outputId": "786c223a-21ee-4e20-b51f-7ed7f728c420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3wvuEUYeMINB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Regression Formulation using Numpy\n",
        "\n",
        "a = np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "b= np.array([2,4,6,8,10,12,14,16,18,20])\n",
        "\n",
        "# (y = 2x)\n",
        "# For accessing we use x[0].ndim we gwt no dimensions as it is an array of scalar values and no dimensions\n",
        "plt.scatter(a,b)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "-OUdSaYFMcGD",
        "outputId": "e6a46c9c-bbfa-43b9-a0b8-89df6f8339e7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Tensorflow or tensors\n",
        "\n",
        "House_features = tf.constant([\"Bedrooms\",\"Bathrooms\",\"Area\"])\n",
        "Price = tf.constant([74000])\n",
        "\n",
        "print(House_features,Price)\n",
        "print(f\"Input Features Shape : {House_features.shape}\")\n",
        "print(f\"Output Shape : {Price.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A5S0rOJNF2s",
        "outputId": "35b2b1bc-8e18-4315-ebd1-0a0e4e36dd1d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'Bedrooms' b'Bathrooms' b'Area'], shape=(3,), dtype=string) tf.Tensor([74000], shape=(1,), dtype=int32)\n",
            "Input Features Shape : (3,)\n",
            "Output Shape : (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting numpy arrays to tensors\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1lucc7uB51cT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.constant(a)\n",
        "y = tf.constant(b)"
      ],
      "metadata": {
        "id": "W6FAhcNYNpnf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X,y)\n",
        "print(f\"Shape of X : {X.shape},  y : {y.shape}\")\n",
        "#But it is a regression probelm so we need X[] scalar value to predict a scalar value y[] respectively\n",
        "print(X[1].shape) # void means 0 dimensions or scalar value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-AzhGr96Azg",
        "outputId": "e623d01b-5974-446f-b16e-5705d941b91d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 1  2  3  4  5  6  7  8  9 10], shape=(10,), dtype=int64) tf.Tensor([ 2  4  6  8 10 12 14 16 18 20], shape=(10,), dtype=int64)\n",
            "Shape of X : (10,),  y : (10,)\n",
            "()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps for modelling a neural network\n",
        "\n",
        "* Make the data into proper format after preprocessing and EDA\n",
        "* One can also pick a model prebuilt or formulate through scratch using the steps (1) below\n",
        "\n",
        "1. Create a model : Define input output and hidden layers\n",
        "2. Compile the model : Define loss function and a optimizer function and evaluation matrix\n",
        "3. Fitting a model : Letting our model try to generalize the predictions using X,y from training set\n",
        "4. Evaluate the model : Evaluate on the testing dataset\n",
        "5. Improve through Experimentation\n",
        "6. Save and load the finetuned model"
      ],
      "metadata": {
        "id": "kEIKnEfg_mAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note :\n",
        "\n",
        "This happens because model.fit() no longer automatically upscales inputs from shape (batch_size, ) to (batch_size, 1).\n",
        "\n",
        "This results in a shape error (remember one of most common errors in deep learning is input and output shapes)."
      ],
      "metadata": {
        "id": "5ZAIwm88htlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(78)\n",
        "\n",
        "# Defining the model\n",
        "model= tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)# will throw error as it requires minimum 2 dimensional X and for our example we have 1 dimensional X\n",
        "\n",
        "])\n",
        "\n",
        "# Compiling\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# Fitting the model\n",
        "# model.fit(X,y,epochs=5) # will throw error\n",
        "model.fit(tf.expand_dims(X,axis=-1),y,epochs=5)\n"
      ],
      "metadata": {
        "id": "xlLDI9w3-0LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54fd37f-c465-438b-c35d-9fe6e0a10c62"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 9.0584 - mae: 9.0584\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7459 - mae: 8.7459\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4334 - mae: 8.4334\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1209 - mae: 8.1209\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.8084 - mae: 7.8084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6f9e714610>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([12])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5Vc0QJZcah4",
        "outputId": "ee655cae-e2cd-4fc2-ad5d-2c1e7c23a222"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 60ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred) # as mae us 5.192 we can say that y lies\n",
        "print(y_pred-5.192,\"<y<\",y_pred+5.192)\n",
        "#Which is still off thus we need to train more and tune the hyperparameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPNSNYkLjZWf",
        "outputId": "ec639ab3-0374-4f8a-8d56-9a9d773adbc1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.586276]]\n",
            "[[2.3942761]] <y< [[12.778276]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving the model\n",
        "\n",
        "Can be done by updating or altering the steps taken while creating a model\n",
        "\n",
        "1. **Adding Layers to Model** : we can also change the number of neurons per layer , the activation function can also be altered to get the desired results\n",
        "\n",
        "2. **Compiling The Model** : here we might change the optimization function or its learning rate\n",
        "\n",
        "3. **Fitting The Model** We might fit the model with more iteration or epochs"
      ],
      "metadata": {
        "id": "n1jXi7GkH4WG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets try optimizing our last model\n",
        "\n",
        "M1 )=> Increasing the epochs"
      ],
      "metadata": {
        "id": "QhzoPjMJQh1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model\n",
        "mod1= tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)# will throw error as it requires minimum 2 dimensional X and for our example we have 1 dimensional X\n",
        "\n",
        "])\n",
        "\n",
        "# Compiling\n",
        "mod1.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# Fitting the model\n",
        "# model.fit(X,y,epochs=5) # will throw error\n",
        "mod1.fit(tf.expand_dims(X,axis=-1),y,epochs=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLlueynxj3CB",
        "outputId": "c075ede7-a50f-483d-8515-891a1a75dcbb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 5.3637 - mae: 5.3637\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.0512 - mae: 5.0512\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7387 - mae: 4.7387\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.4262 - mae: 4.4262\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1137 - mae: 4.1137\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8012 - mae: 3.8012\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4887 - mae: 3.4887\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1762 - mae: 3.1762\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8637 - mae: 2.8637\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5512 - mae: 2.5512\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2387 - mae: 2.2387\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9262 - mae: 1.9262\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6137 - mae: 1.6137\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3012 - mae: 1.3012\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9887 - mae: 0.9887\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6762 - mae: 0.6762\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3767 - mae: 0.3767\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1143 - mae: 0.1143\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1763 - mae: 0.1763\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1685 - mae: 0.1685\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1393 - mae: 0.1393\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2003 - mae: 0.2003\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1023 - mae: 0.1023\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2321 - mae: 0.2321\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0677 - mae: 0.0677\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1647 - mae: 0.1647\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1403 - mae: 0.1403\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1965 - mae: 0.1965\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1033 - mae: 0.1033\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2283 - mae: 0.2283\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0667 - mae: 0.0667\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1609 - mae: 0.1609\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1413 - mae: 0.1413\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1927 - mae: 0.1927\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1043 - mae: 0.1043\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2245 - mae: 0.2245\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0673 - mae: 0.0673\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2576 - mae: 0.2576\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0571 - mae: 0.0571\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1681 - mae: 0.1681\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1293 - mae: 0.1293\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1999 - mae: 0.1999\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0923 - mae: 0.0923\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2322 - mae: 0.2322\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0793 - mae: 0.0793\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2444 - mae: 0.2444\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0663 - mae: 0.0663\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2566 - mae: 0.2566\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0545 - mae: 0.0545\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1655 - mae: 0.1655\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1283 - mae: 0.1283\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1973 - mae: 0.1973\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0913 - mae: 0.0913\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2312 - mae: 0.2312\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0783 - mae: 0.0783\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2434 - mae: 0.2434\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0653 - mae: 0.0653\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2556 - mae: 0.2556\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0523 - mae: 0.0523\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2678 - mae: 0.2678\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0447 - mae: 0.0447\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0875 - mae: 0.0875\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1803 - mae: 0.1803\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1469 - mae: 0.1469\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1433 - mae: 0.1433\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1788 - mae: 0.1788\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1303 - mae: 0.1303\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1910 - mae: 0.1910\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1173 - mae: 0.1173\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2032 - mae: 0.2032\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1043 - mae: 0.1043\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2154 - mae: 0.2154\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0913 - mae: 0.0913\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2276 - mae: 0.2276\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0783 - mae: 0.0783\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2398 - mae: 0.2398\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0653 - mae: 0.0653\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2520 - mae: 0.2520\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0523 - mae: 0.0523\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2642 - mae: 0.2642\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0397 - mae: 0.0397\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1688 - mae: 0.1688\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1383 - mae: 0.1383\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1810 - mae: 0.1810\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1253 - mae: 0.1253\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1932 - mae: 0.1932\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1123 - mae: 0.1123\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2054 - mae: 0.2054\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0993 - mae: 0.0993\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2176 - mae: 0.2176\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0863 - mae: 0.0863\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2298 - mae: 0.2298\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0733 - mae: 0.0733\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2420 - mae: 0.2420\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0603 - mae: 0.0603\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2542 - mae: 0.2542\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0473 - mae: 0.0473\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2664 - mae: 0.2664\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0343 - mae: 0.0343\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2786 - mae: 0.2786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6f9e5ce950>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = mod1.predict([12])\n",
        "print(f\"predicted:{y_pred} \\nactual :{12*2}\") # which is very close\n",
        "print(y_pred-0.2786,\"<y<\",y_pred+0.2786)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGgoUZoZQyyk",
        "outputId": "216ee660-f5c5-4d51-f7b1-11521b31c0e6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n",
            "predicted:[[23.961384]] \n",
            "actual :24\n",
            "[[23.682783]] <y< [[24.239985]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. mod2)=> We will add a layer and change the oprtimization function"
      ],
      "metadata": {
        "id": "hcuwihVWfs1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod2 =  tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "mod2.compile(loss=tf.keras.losses.mae,\n",
        "             optimizer = tf.keras.optimizers.Adam(lr=0.1199),\n",
        "             metrics = [\"mae\"])\n",
        "mod2.fit(tf.expand_dims(X,axis = -1),y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVZpiHW8Rbyg",
        "outputId": "7220cc52-9016-45dc-ddd0-12cdd2f2efb8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 593ms/step - loss: 9.2133 - mae: 9.2133\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.1429 - mae: 9.1429\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0730 - mae: 9.0730\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0033 - mae: 9.0033\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9335 - mae: 8.9335\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8635 - mae: 8.8635\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.7933 - mae: 8.7933\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7228 - mae: 8.7228\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6522 - mae: 8.6522\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5814 - mae: 8.5814\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5105 - mae: 8.5105\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.4392 - mae: 8.4392\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3679 - mae: 8.3679\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.2963 - mae: 8.2963\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.2246 - mae: 8.2246\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1528 - mae: 8.1528\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.0812 - mae: 8.0812\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.0096 - mae: 8.0096\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9377 - mae: 7.9377\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.8657 - mae: 7.8657\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.7936 - mae: 7.7936\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.7218 - mae: 7.7218\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.6496 - mae: 7.6496\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.5771 - mae: 7.5771\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.5042 - mae: 7.5042\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4311 - mae: 7.4311\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.3576 - mae: 7.3576\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2838 - mae: 7.2838\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2097 - mae: 7.2097\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1354 - mae: 7.1354\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0611 - mae: 7.0611\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9868 - mae: 6.9868\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9120 - mae: 6.9120\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8369 - mae: 6.8369\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7614 - mae: 6.7614\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6854 - mae: 6.6854\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6090 - mae: 6.6090\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5321 - mae: 6.5321\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4548 - mae: 6.4548\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3771 - mae: 6.3771\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2990 - mae: 6.2990\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2205 - mae: 6.2205\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.1415 - mae: 6.1415\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0622 - mae: 6.0622\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.9825 - mae: 5.9825\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.9024 - mae: 5.9024\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.8219 - mae: 5.8219\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7407 - mae: 5.7407\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6589 - mae: 5.6589\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5764 - mae: 5.5764\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4933 - mae: 5.4933\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4095 - mae: 5.4095\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3251 - mae: 5.3251\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2400 - mae: 5.2400\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.1542 - mae: 5.1542\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.0677 - mae: 5.0677\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9806 - mae: 4.9806\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8927 - mae: 4.8927\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.8041 - mae: 4.8041\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7148 - mae: 4.7148\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.6249 - mae: 4.6249\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5341 - mae: 4.5341\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.4427 - mae: 4.4427\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3505 - mae: 4.3505\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2576 - mae: 4.2576\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1639 - mae: 4.1639\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0694 - mae: 4.0694\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9742 - mae: 3.9742\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8783 - mae: 3.8783\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7815 - mae: 3.7815\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6840 - mae: 3.6840\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.5857 - mae: 3.5857\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4867 - mae: 3.4867\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3868 - mae: 3.3868\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2861 - mae: 3.2861\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1846 - mae: 3.1846\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0824 - mae: 3.0824\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9793 - mae: 2.9793\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8798 - mae: 2.8798\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7813 - mae: 2.7813\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6825 - mae: 2.6825\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5832 - mae: 2.5832\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4835 - mae: 2.4835\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3833 - mae: 2.3833\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2826 - mae: 2.2826\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1813 - mae: 2.1813\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0794 - mae: 2.0794\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9769 - mae: 1.9769\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8738 - mae: 1.8738\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7699 - mae: 1.7699\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6655 - mae: 1.6655\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5602 - mae: 1.5602\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4617 - mae: 1.4617\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3656 - mae: 1.3656\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2695 - mae: 1.2695\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1733 - mae: 1.1733\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0770 - mae: 1.0770\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9805 - mae: 0.9805\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8911 - mae: 0.8911\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8084 - mae: 0.8084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6f89547970>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = mod2.predict([12])\n",
        "print(f\"predicted:{y_pred} \\nactual :{12*2}\") # which is very close comparatively to the base model\n",
        "print(y_pred-0.8084,\"<y<\",y_pred+0.8084)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGlI7sdmdKRd",
        "outputId": "7e471579-f285-4e82-c365-2d98060b9d21"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 58ms/step\n",
            "predicted:[[21.861393]] \n",
            "actual :24\n",
            "[[21.052994]] <y< [[22.669792]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZPNmneDJfbOA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}